{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('cademycode.db')\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list = [a for a in cur.execute(\"SELECT name FROM sqlite_master WHERE type = 'table'\")]\n",
    "print(table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = pd.read_sql_query(\"SELECT * FROM cademycode_students\", con)\n",
    "career_paths = pd.read_sql_query(\"SELECT * FROM cademycode_courses\", con)\n",
    "student_jobs = pd.read_sql_query(\"SELECT * FROM cademycode_student_jobs\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('students: ', len(students))\n",
    "print('career_paths: ', len(career_paths))\n",
    "print('student_jobs: ', len(student_jobs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the `Students` table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the head of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`contact_info` has a JSON format, might be a good idea to look into this later. Let's look at column data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there is missing data in the last 4 columns of the dataframe. We have to make sure that `dob` is in datetime format that we can use to determine each student's age for better grouping. Numerical columns should be either integers or floats. We can also treat `job_id` and `current_career_path_id` as categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students[students.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No pattern can be found, we can only tell that there are 707 rows that have AT LEAST ONE null value in their columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating approximate age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an `age` column within our dataframe, we will have to use the `pd.to_datetime` function. We will also create an `age_group` column that should help us better classify our students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "students['age'] = (now - pd.to_datetime(students['dob'])).dt.days // 365\n",
    "students['age_group'] = (students['age'] // 10)*10\n",
    "students.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explode the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to extract all the information from the ``contact_info`` column so we can have an individual column for each key from the dictionary. First, let's take a look at the data type for said column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(students['contact_info'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how this column is made up of strings rather than dictionaries. We need to transform this column into dictionaries in order to extract the info with the help of `pd.json_normalize`. Here is how we can implement this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students['contact_info'] = students['contact_info'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have transformed our `contact_info` column into a set of dictionaries, we can extract the information with the following methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explode_contact_info = pd.json_normalize(students['contact_info'])\n",
    "explode_contact_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed to concatenate this dataframe with our original `students` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = pd.concat([students.drop('contact_info', axis=1), explode_contact_info], axis=1)\n",
    "students.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will further split our `contact_info` to extract more bits of information for each student. Notice how `mailing_address` contains street name, city, state, and zip code. This is valuable information that the analytics team might want to explore further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_address = students.mailing_address.str.split(',', expand=True)\n",
    "split_address.columns = ['street', 'city', 'state', 'zip_code']\n",
    "split_address.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will include this dataframe into our `students` dataframe and drop the `mailing_address` column in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = pd.concat([students.drop('mailing_address', axis=1), split_address], axis=1)\n",
    "students.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now take a look at our data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing column data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to change the data type for certain columns so we can use them for analysis down the line. We know that `num_course_taken` should be an integer value, and `time_spent_hrs` should be a float. Since there is some null data for `job_id` and `current_career_path_id`, we have to cast them into floats instead of integers for the time being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students['job_id'] = students['job_id'].astype(float)\n",
    "students['current_career_path_id'] = students['current_career_path_id'].astype(float)\n",
    "students['num_course_taken'] = students['num_course_taken'].astype(float)\n",
    "students['time_spent_hrs'] = students['time_spent_hrs'].astype(float)\n",
    "students.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the missing data for `job_id`, `num_course_taken`, `current_career_path_id` and `time_spent_hrs` one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_course_taken = students[students[['num_course_taken']].isnull().any(axis=1)]\n",
    "display(missing_course_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distributions of the missing and complete data for `num_course_taken` side by side. If both distributions look similar, we can conclude that the data is missing at random if there is no identifiable pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_group = (students.groupby('sex').count()['uuid']/len(students)).rename('complete')\n",
    "missing_group = (missing_course_taken.groupby('sex').count()['uuid']/len(missing_course_taken)).rename('incomplete')\n",
    "df = pd.concat([students_group, missing_group], axis=1)\n",
    "df.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_group = (students.groupby('job_id').count()['uuid']/len(students)).rename('complete')\n",
    "missing_group = (missing_course_taken.groupby('job_id').count()['uuid']/len(missing_course_taken)).rename('incomplete')\n",
    "df = pd.concat([students_group, missing_group], axis=1)\n",
    "df.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_group = (students.groupby('age_group').count()['uuid']/len(students)).rename('complete')\n",
    "missing_group = (missing_course_taken.groupby('age_group').count()['uuid']/len(missing_course_taken)).rename('incomplete')\n",
    "df = pd.concat([students_group, missing_group], axis=1)\n",
    "df.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the distributions side-by-side, we can see that they share some similarities. This means we can conclude that the data for `num_course_taken` is missing at random, since there is not identifiable pattern for all these distributions.\n",
    "\n",
    "Now, we don't want to remove this data completely. Instead, we are going to store it in an alternate DataFrame and remove it from the main one since it accounts for less than 5% of the data. The reason to keep this information apart is that perhaps the analytics team might want to look into it with more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = pd.DataFrame()\n",
    "missing_data = pd.concat([missing_data, missing_course_taken])\n",
    "students = students.dropna(subset=['num_course_taken'])\n",
    "students.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to look into the `job_id`. It is important to note that this data is categorical and we also cannot impute it. Let's take a look at what we are dealing with in terms of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_job_id = students[students[['job_id']].isnull().any(axis=1)]\n",
    "display(missing_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 5 missing rows. Sample is too small compared to the total amount of data, so we can safely remove it from the Dataframe. We are going to store it in our `missing_data` df and drop it from the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = pd.concat([missing_data, missing_job_id])\n",
    "students = students.dropna(subset=['job_id'])\n",
    "students.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `current_career_path_id`, let's look at how much data we are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_path_id = students[students[['current_career_path_id']].isnull().any(axis=1)]\n",
    "display(missing_path_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `current_career_path_id` and `time_spent_hrs` are missing in the same instances since students are not enrolled in any career paths, and therefore not taking any classes. Let's run the following to be certain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_path_id.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the amount of data is more than 5%, we would assign a new category for people with missing `current_career_path_id` and their `time_spent_hrs` will be set to 0, since they are not taking any classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students['current_career_path_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students['current_career_path_id'] = np.where(students['current_career_path_id'].isnull(), 0, students['current_career_path_id'])\n",
    "students['time_spent_hrs'] = np.where(students['time_spent_hrs'].isnull(), 0, students['time_spent_hrs'])\n",
    "students.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the `career_paths` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(career_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "career_paths.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this table does not need any changes at first glance. However, since we added a new category to `career_path_id`, we need to add a new option for students not taking any career paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_applicable = {'career_path_id': 0,\n",
    "                  'career_path_name': 'not applicable',\n",
    "                  'hours_to_complete': 0}\n",
    "\n",
    "career_paths.loc[len(career_paths)] = not_applicable # type: ignore\n",
    "display(career_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the `students_jobs` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(student_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_jobs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only issue with this table is that there are some duplicates to be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_jobs.drop_duplicates(inplace=True)\n",
    "display(student_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining the tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to change the data type for `job_id` and `current_career_path_id` from the students to int data type before performing our join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students['job_id'] = students['job_id'].astype(int)\n",
    "students['current_career_path_id'] = students['current_career_path_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform our joins with the other two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_full_info = students.merge(career_paths, left_on='current_career_path_id', right_on='career_path_id', how='left')\n",
    "students_full_info = students_full_info.merge(student_jobs, on='job_id', how='left')\n",
    "display(students_full_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_full_info.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New SQLite DB to upsert cleansed and missing data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_connection = sqlite3.connect('cademycode_cleansed.db')\n",
    "students_full_info.to_sql('cademycode_aggregated', sqlite_connection, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_info_db = pd.read_sql_query(\"SELECT * FROM cademycode_aggregated\", sqlite_connection)\n",
    "full_info_db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_info_db.to_csv('cademycode_cleansed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data.to_sql('incomplete_data', sqlite_connection, if_exists='replace', index=False)\n",
    "\n",
    "missing_info = pd.read_sql_query(\"SELECT * FROM incomplete_data\", sqlite_connection)\n",
    "missing_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(missing_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
